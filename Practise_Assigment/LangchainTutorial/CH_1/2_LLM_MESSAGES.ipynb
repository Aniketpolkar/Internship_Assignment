{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2af413",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137fbf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key is loaded\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from load_dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    print(\"API Key is loaded\")\n",
    "else:\n",
    "    print(\"API Key is not loaded\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7e84e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG, bestie, buckle up 'cause I got the *tea*! ðŸ’…\n",
      "\n",
      "Did you know that a group of **flamingos** is called a **\"flamboyance\"**?! ðŸ¤¯\n",
      "\n",
      "Like, can you even?! They're just out here living their most extra, pink, fabulous lives. Slay, flamingos, *slay*! âœ¨\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite-preview-09-2025\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "myMessages = [\n",
    "    HumanMessage(content=\"You are a gen-z assistant which answers in a fun way\"),\n",
    "    HumanMessage(content=\"Bro, tell me a fun fact\"),\n",
    "]\n",
    "\n",
    "response = llm_gemini.invoke(myMessages)\n",
    "print(response.content) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d39df1",
   "metadata": {},
   "source": [
    "## **Prompts**\n",
    "Prompts are messages that are sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b33b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a fun fact about rainbows:\\n\\n**A rainbow is actually a full circle!** We usually only see an arc because the ground gets in the way. If you were in an airplane or on a very high mountain, you could potentially see the entire, glorious circle!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "user_input = input(\"Enter a topic for fun fact: \")\n",
    "\n",
    "dynamic_prompt = PromptTemplate.from_template(\"Give me a fun fact about {topic}\")   \n",
    "\n",
    "ready_prompt = dynamic_prompt.invoke({\"topic\": user_input})\n",
    "\n",
    "llm_gemini.invoke(ready_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a fun fact about chai!\\n\\n```json\\n{\\n  \"fact\": \"The word \\'chai\\' actually just means \\'tea\\' in Hindi, so when you ask for \\'chai tea,\\' you\\'re essentially asking for \\'tea tea\\'! How wonderfully redundant and delicious!\"\\n}\\n```'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a {tone} assistant \"),\n",
    "    (\"user\",\"Write a fun fact about {topic}.\")\n",
    "])\n",
    "\n",
    "user_tone = input(\"Enter a tone? \")\n",
    "user_input = input(\"Enter a topic? \")\n",
    "ready_prompt = prompt_template.invoke({\"topic\": user_input, \"tone\": user_tone})\n",
    "llm_gemini.invoke(ready_prompt.messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad7703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
